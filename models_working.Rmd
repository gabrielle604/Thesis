---
title: "models_working"
author: "Gabrielle"
date: "2023-02-18"
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(here)
library(ggpubr) # for some graphic applications that extend ggplot2
library(janitor)
library(broom) # used to make tables
library(knitr) # used to make table
library(car) # has leveneTest 
library(foreign) # to read in NHANES data
library(rstanarm) # for the model fitting
library(jtools) # Load jtools, for forest plots
library(sandwich) # needed for robust standard errors in forest plot
library(huxtable) # needed to be able to export table of forest plot values
library(broom.mixed) # used in making tables
library(visdat)
library(ggplot2)

library(haven) # for reading SAS XPT file from NHANES website
library(survey) # for using survey weights
library(dplyr) # for data wrangling
library(forcats)

library("remotes")
library("svrepmisc")

```

## Load the data
```{r}
fullNHANES_recat <- read_csv(here("cleaned_data","fullNHANES_recat.csv"))
```
## The svydesign function

Before we can start our analyses, we need to use the svydesign function from the “survey” package written by Thomas Lumley. The svydesign function tells R about the design elements in the survey. Once this command has been issued, all that needs to be done for the analyses is use the object that contains this information in each command. Because the 2001-2016 NHANES data were released with a sampling weight (wtint2yr), a PSU variable (sdmvpsu) and a strata variable (sdmvstra), we will use these our svydesign function. 

```{r}
nhc <- svydesign(id=~SDMVPSU, weights=~WTINT2YR,strata=~SDMVSTRA, nest=TRUE, survey.lonely.psu = "adjust", data=fullNHANES_recat)
nhc
```

## We can get additional information about the sample, such as the number of PSUs per strata, by using the summary function.

```{r}
summary(nhc)
```

## Subpopulation Analysis

Complex survey data are unique. With survey data, you (almost) never get to delete any cases from the data set, even if you will never use them in any of your analyses. 
Instead, the survey package has two options that allow you to correctly analyze subpopulations of your survey data. 

These options are 'svyby' and 'subset.survey.design'. 

The subset.survey.design option is sort of like deleting unwanted cases (without really deleting them, of course), and the svyby option is very similar to by-group processing in that the results are shown for each group of the by-variable.

### Why deleting cases from a survey data set can be so problematic:

There are two formulas that can used to calculate the standard errors. 

One formula is used when you do by-group processing or delete unwanted cases from the dataset, and survey statisticians call this the conditional approach. This is used when members of the subpopulation cannot appear in certain strata and therefore those strata should not be used in the calculation of the standard error. In practice, this rarely happens in public-use complex survey datasets. One reason is because the analyst usually does not know which combination of variables defines a particular stratum.

The other formula is used when you use the svyby option, and survey statisticians call this the unconditional approach. 
This is used when members of the subpopulation can be in any of the strata, even if there are some strata in the sample data that do not contain any members of the subpopulation. 

Because members of the subpopulation, all of the strata need to be used in the calculation of the standard error, and hence all of the data must be in the dataset. 

If the data set is subset (meaning that observations not to be included in the subpopulation are deleted from the data set), the standard errors of the estimates cannot be calculated correctly. When the svyby option is used, only the cases defined by the subpopulation are used in the calculation of the estimate, but all cases are used in the calculation of the standard errors. 

[For more information on this issue, please see Sampling Techniques, Third Edition by William G. Cochran (1977) and Small Area Estimation by J. N. K. Rao (2003). A nice description of this issue given in Brady West’s 2009 Stata Conference (in Washington, D.C.).]

Both svyby and subset.svy.design use the formula for the unconditional standard errors.

## Mean of age

```{r}
svymean(~RIDAGEYR, nhc)
```

## Mean of mono-ethyl phthalate
(need to tell R to skip the missing values)
```{r}
svymean(~URXMEP, nhc, na.rm = TRUE)
```

## Mean of age for males and females. 
The variable female is the subpopulation variable.

```{r}
svyby(~RIDAGEYR, ~gender, nhc, svymean)
```
## the highest grade level of education completed by participants 6-19 y.o. (DMDEDU3)
Primary = 0:8
Secondary = 9:15
```{r}
svyby(~DMDEDUC3, ~age, nhc, svymean, na.rm = TRUE)
```

## Can use more than one categorical variable to define the subpopulation. 
To do so, put + between the variables.

```{r}
svyby(~RIDAGEYR, ~refED+gender, nhc, svymean)
```

Three variables are used.

```{r}
svyby(~log(monoEthyl), ~refED+citizenship+gender, nhc, na = TRUE, svymean)
```

Sometimes you don’t want so much output. Rather, you just want the output for a specific group. You can get this by creating a subpopulation of the data with the subset function. In the example below, we obtain the output only for males.

```{r}
smale <- subset(nhc,gender == "male")
summary(smale)
```


```{r}
svymean(~RIDAGEYR,design=smale)
```

## log(monoEthyl) level for children

```{r}
schild <- subset(nhc,age == "child")
summary(schild)
```

```{r}
svymean(~log(monoEthyl), design = schild, na.rm = TRUE)
```

## log(monoEthyl) level for young adult 

```{r}
syadult <- subset(nhc,age == "young adult")
summary(syadult)
```

```{r}
svymean(~log(monoEthyl), design = syadult, na.rm = TRUE)
```

## log(monoEthyl) level for middle-aged

```{r}
smid <- subset(nhc,age == "middle-aged")
summary(smid)
```

```{r}
svymean(~log(monoEthyl), design = smid, na.rm = TRUE)
```

## log(monoEthyl) level for older adult

```{r}
soadult <- subset(nhc,age == "older adult")
summary(soadult)
```

```{r}
svymean(~log(monoEthyl), design = soadult, na.rm = TRUE)
```
### highest level of phthlates for young adult category

## Models

A wide variety of statistical models can be run with complex survey data. 

With only a few exceptions, the results of these analyses can be interpreted just as the results from the same analyses with experimental or quasi-experimental data. 

For example, if you run an OLS regression with weighted data, assuming that the sampling plan has been correctly specified, the regression coefficients are interpreted exactly as any other OLS regression coefficient. 

The same is true for the various logistic regression models, including binary logistic regression, ordinal logistic regression and multinomial logistic regression (of which there is not an example in this workshop).

Most of the assumptions of these models are also the same. However, some assumptions, such as the assumption regarding the normality of the residuals in OLS regression, are often not meaningful because of the large sample size commonly seen with complex survey data.

### t tests

```{r}
svyttest(log(monoEthyl)~0, nhc, na = TRUE)
```

## Independent-samples t-test.

```{r}
svyttest(log(monoEthyl)~refED, nhc)
```

As you probably know, an independent-samples t-test tests the null hypothesis that the difference in the means of the two groups is 0. Another way to think about this type of t-test is to think of it as a linear regression with a single binary predictor. The intercept will be the mean of the reference group, and the coefficient will be the difference between the two groups.

We will start by running the t-test function as before, and then replicate the results using the svyglm function, which can be used to run a linear regression. The svyby function is used with the covmat argument to save the elements to a matrix so that we can use the svycontrast function to subtract the values. 

The purpose of this example is not to belabor the point about a t-test, but rather to show how to get a matrix of values and then compare those values with the svycontrast function in a simple example where the answer is already known.

```{r}
svyttest(RIDAGEYR~gender, nhc)
```

```{r}
summary(svyglm(RIDAGEYR~gender, design=nhc))
```

```{r}
a <- svyby(~RIDAGEYR, ~gender, nhc, na.rm.by = TRUE, svymean, covmat = TRUE)
vcov(a)
```

```{r}
svycontrast(a, c( -1, 1))
```

## Multiple linear regression

We need to use the summary function to get the standard errors, test statistics and p-values. 
Let’s start with a model that has no interaction terms.  
The outcome variable will be monoEthyl, and the predictors will be age and refED

```{r}
summary(svyglm(log(monoEthyl)~age+refED, design=nhc, na.action = na.omit))

```

### Interaction
Now let’s add an interaction between the two predictor variables, age and reference person education 

```{r}
summary(svyglm(log(monoEthyl)~age*refED, design=nhc, na.action = na.omit))
```

```{r}
glm1 <- (svyglm(log(monoEthyl)~gender+refED, design=nhc, na.action = na.omit))
glm1
```
This example is just like the previous one, only here factor notation is used. 
This is important when the categorical predictor has more than two levels.

```{r}
summary(svyglm(log(monoEthyl)~factor(gender)+factor(ethnicity), design=nhc, na.action = na.omit))
```










## Forest Models

### Forest model for Model A:
#### multivariate regression analysis of socio-demographic variables and phthalates
```{r}
modela <- svyglm(log(monoEthyl)~refED+age+gender+ethnicity+fpl+citizenship, design=nhc, na.action = na.omit)

summ(modela)

summ(modela, robust = "HC1") #robust standard errors 

summ(modela, confint = TRUE, digits = 3) #In many cases, you’ll learn more by looking at confidence intervals than p-values. You can request them from summ. default is 95% CIs

summ(modela, confint = TRUE, pvals = FALSE) #DROP the p values all together

# THE GRAPH
plot_summs(modela)
plot_summs(modela, robust = TRUE)
plot_summs(modela, inner_ci_level = .9)

# plot coefficient uncertainty as normal distributions
plot_summs(modela, plot.distributions = TRUE, inner_ci_level = .9)

# table output for Word and RMarkdown documents
## error is in the parenthesis
export_summs(modela, scale = TRUE)

# confidence intervals instead of standard errors
export_summs(modela, scale = TRUE,
             error_format = "[{conf.low}, {conf.high}]")

```

#### renaming variables in the forest plot

```{r}
foresta <- plot_summs(
        point.size = 3,
        fontsize=8,
        colors = "darkseagreen3",
        modela, coefs = c("Household Education Partial College and Below
                                 College and Beyond (ref)" = "refEDpartial college and below", 
                          
                                 "Age: Middle-Aged
                                 Child (ref)" = "agemiddle-aged",
                          
                                 "Age: Older Adult
                                 Child (ref)" = "ageolder adult",
                          
                                 "Age: Young Adult
                                 Child (ref)" = "ageyoung adult",
                          
                                 "Gender: Male
                                 Gender: Female (ref)" = "gendermale",
                          
                                 "Ethnicity: Non-Hispanic Black
                                 Mexican American (ref)" = "ethnicityNon-Hispanic Black",
                          
                                 "Ethnicity: Non-Hispanic White
                                 Mexican American (ref)" = "ethnicityNon-Hispanic White",
                          
                                 "Ethnicity: Other Hispanic
                                 Mexican American (ref)" = "ethnicityOther Hispanic",
                          
                                 "Ethnicity: Other or Multi
                                 Mexican American (ref)" = "ethnicityOther or Multi",
                          
                                 "Family Income to Poverty Ratio: 2x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income 2x poverty threshold",
                          
                                 "Family Income to Poverty Ratio: 3x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income 3x poverty threshold",
                          
                                 "Family Income to Poverty Ratio: 4x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income 4x poverty threshold",
                          
                                 "Family Income to Poverty Ratio: 5x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income 5x poverty threshold",
                          
                                 "Family Income to Poverty Ratio: more than 5x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income more than 5x poverty threshold",
                          
                                 "Citizenship Status: Not U.S. Citizen
                                 U.S. Citizen by birth or naturalization (ref)" = "citizenshipnot U,S, citizen"),
        
                          scale = TRUE, robust = TRUE)

foresta
```

### Forest Model for Model B:
##### take out gender

```{r}
modelb <- svyglm(log(monoEthyl)~refED+age+ethnicity+fpl+citizenship, design=nhc, na.action = na.omit)

summ(modelb)

summ(modelb, robust = "HC1") #robust standard errors 

summ(modelb, confint = TRUE, digits = 3) #In many cases, you’ll learn more by looking at confidence intervals than p-values. You can request them from summ. default is 95% CIs

summ(modelb, confint = TRUE, pvals = FALSE) #DROP the p values all together

# THE GRAPH
plot_summs(modelb)
plot_summs(modelb, inner_ci_level = .9)
plot_summs(modelb, robust = TRUE)

# plot coefficient uncertainty as normal distributions
plot_summs(modelb, plot.distributions = TRUE, inner_ci_level = .9)

# table output for Word and RMarkdown documents
## error is in the parenthesis
export_summs(modelb, scale = TRUE)

# confidence intervals instead of standard errors
export_summs(modelb, scale = TRUE,
             error_format = "[{conf.low}, {conf.high}]")

```

#### renaming variables in the forest plot

```{r}
forestb <- plot_summs(
        point.size = 3,
        fontsize=8,
        colors = "darkslateblue",
        modela, coefs = c("Household Education Partial College and Below
                                 College and Beyond (ref)" = "refEDpartial college and below", 
                          
                                 "Age: Middle-Aged
                                 Child (ref)" = "agemiddle-aged",
                          
                                 "Age: Older Adult
                                 Child (ref)" = "ageolder adult",
                          
                                 "Age: Young Adult
                                 Child (ref)" = "ageyoung adult",
                          
                                 "Ethnicity: Non-Hispanic Black
                                 Mexican American (ref)" = "ethnicityNon-Hispanic Black",
                          
                                 "Ethnicity: Non-Hispanic White
                                 Mexican American (ref)" = "ethnicityNon-Hispanic White",
                          
                                 "Ethnicity: Other Hispanic
                                 Mexican American (ref)" = "ethnicityOther Hispanic",
                          
                                 "Ethnicity: Other or Multi
                                 Mexican American (ref)" = "ethnicityOther or Multi",
                          
                                 "Family Income to Poverty Ratio: 2x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income 2x poverty threshold",
                          
                                 "Family Income to Poverty Ratio: 3x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income 3x poverty threshold",
                          
                                 "Family Income to Poverty Ratio: 4x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income 4x poverty threshold",
                          
                                 "Family Income to Poverty Ratio: 5x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income 5x poverty threshold",
                          
                                 "Family Income to Poverty Ratio: more than 5x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income more than 5x poverty threshold",
                          
                                 "Citizenship Status: Not U.S. Citizen
                                 U.S. Citizen by birth or naturalization (ref)" = "citizenshipnot U,S, citizen"),
        
                          scale = TRUE, robust = TRUE)

forestb
```

### Model C
##### take out gender, citizenship

```{r}
modelc <- svyglm(log(monoEthyl)~refED+age+ethnicity+fpl, design=nhc, na.action = na.omit)

summ(modelc)

summ(modelc, robust = "HC1") #robust standard errors 

summ(modelc, confint = TRUE, digits = 3) #In many cases, you’ll learn more by looking at confidence intervals than p-values. You can request them from summ. default is 95% CIs

summ(modelc, confint = TRUE, pvals = FALSE) #DROP the p values all together

# THE GRAPH
plot_summs(modelc)
plot_summs(modelc, inner_ci_level = .9)
plot_summs(modelc, robust = TRUE)

# plot coefficient uncertainty as normal distributions
plot_summs(modelc, plot.distributions = TRUE, inner_ci_level = .9)

# table output for Word and RMarkdown documents
## error is in the parenthesis
export_summs(modelc, scale = TRUE)

# confidence intervals instead of standard errors
export_summs(modelc, scale = TRUE,
             error_format = "[{conf.low}, {conf.high}]")

```

#### renaming variables in the forest plot

```{r}
forestc <- plot_summs(
        point.size = 3,
        fontsize=8,
        colors = "deepskyblue4",
        modela, coefs = c("Household Education Partial College and Below
                                 College and Beyond (ref)" = "refEDpartial college and below", 
                          
                                 "Age: Middle-Aged
                                 Child (ref)" = "agemiddle-aged",
                          
                                 "Age: Older Adult
                                 Child (ref)" = "ageolder adult",
                          
                                 "Age: Young Adult
                                 Child (ref)" = "ageyoung adult",
                          
                                 "Ethnicity: Non-Hispanic Black
                                 Mexican American (ref)" = "ethnicityNon-Hispanic Black",
                          
                                 "Ethnicity: Non-Hispanic White
                                 Mexican American (ref)" = "ethnicityNon-Hispanic White",
                          
                                 "Ethnicity: Other Hispanic
                                 Mexican American (ref)" = "ethnicityOther Hispanic",
                          
                                 "Ethnicity: Other or Multi
                                 Mexican American (ref)" = "ethnicityOther or Multi",
                          
                                 "Family Income to Poverty Ratio: 2x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income 2x poverty threshold",
                          
                                 "Family Income to Poverty Ratio: 3x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income 3x poverty threshold",
                          
                                 "Family Income to Poverty Ratio: 4x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income 4x poverty threshold",
                          
                                 "Family Income to Poverty Ratio: 5x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income 5x poverty threshold",
                          
                                 "Family Income to Poverty Ratio: more than 5x Poverty threshold
                                 At poverty threshold (ref)" = "fplfamily income more than 5x poverty threshold"),
        
                          scale = TRUE, robust = TRUE)

forestc
```










## Bayesian Information Criterion (BIC)
The model that performs best is Model B, a simple linear regression showing the logged mono-ethyl phthalate as a function of the reference person's education level, the participant's age, the participant's ethnicity, the participant's family income to poverty ratio, and the participant's citizenship status.

XXX The delta BIC for Model C is 72.136, which is far beyond the BIC <7 threshold, so it is a very unlikely model, and therefore, we will dismiss Model C. This reinforces the idea that citizenship status matters substantially to the question of determining the logged phthalate level in individuals.

XXX Model A and Model B are quite similar - the only difference is that Model B does not include gender. Model A, which is the model performing second best, has a delta BIC = 6.590 (and still under the BIC < 7 threshold). 

## ANOVA

An ANOVA test is a type of statistical test used to determine if there is a statistically significant difference between two or more categorical groups by testing for differences of means using variance.


## Wald test

A parametric statistical measure to confirm whether a set of independent variables are collectively 'significant' for a model or not

```{r, results = TRUE}

modela<-svyglm(log(monoEthyl)~refED+age+gender+ethnicity+fpl+citizenship, design=nhc, na.action = na.omit)

modelb<-svyglm(log(monoEthyl)~refED+age+ethnicity+fpl+citizenship, design=nhc, na.action = na.omit)

modelc<-svyglm(log(monoEthyl)~refED+age+ethnicity+fpl, design=nhc, na.action = na.omit)

modeld<-svyglm(log(monoEthyl)~age+ethnicity+fpl, design=nhc, na.action = na.omit)

modele<-svyglm(log(monoEthyl)~refED+age+ethnicity+fpl+citizenship+childED, design=nhc, na.action = na.omit)

########## BIC
BIC(modela, modelb, maximal=modela)
BIC(modelb, modelc, maximal=modelb)
BIC(modela, modelc, maximal=modela)
BIC(modela, modelb, modelc, maximal=modela)

### ???? see questions in "meetings with susie" google doc

BIC_list <- c(BIC(modela, maximal=modela), BIC(modelb, maximal=modela), BIC(modelc, maximal=modela))

model_output <- rbind(data.frame(glance(modela)), data.frame(glance(modelb)), data.frame(glance(modelc))) %>% select(BIC)

model_output <- mutate(model_output, delta.BIC = BIC-min(BIC_list))
model_output$model <- c("Model A", "Model B", "Model C")
model_output <- model_output[,c("model", "BIC", "delta.BIC")]

kable(model_output, format = "markdown", digits = 3, caption = "BIC, and Delta.BIC for the models. Delta BIC > 7 indicates models that should be dismissed from further consideration.")


########## ANOVA
########## Wald test
anova(modela)
anova(modelc, modela)
anova(modela, modelb, method = "Wald")
# wald test for gender, p =-.86238
anova(modelb, modelc, method = "Wald")
# wald test for citizenship, p =0.0045171
anova(modela, modelc, method = "Wald")
# wald test for gender citizenship, p = 0.015958
anova(modela, modeld, method = "Wald")
# wald test for refeD gender citizenship, p = 2.1802e-11

anova(modele)
# anova(modela, modele, method = "Wald")
## cannot do a wald test due to models having different number of observations... does this mean that childED is only using 34% of the data, because 66% of it is missing
vis_miss(fullNHANES_recat, sort_miss = TRUE)
```








## Boxplots, bivariate analyses
```{r}
# change the noNAs dataset with each boxplot I create:
## one for: refED age gender ethnicity fpl citizenship

noNAs = fullNHANES_recat %>% filter(!is.na(citizenship)) %>% filter(!is.na(monoEthyl))
                                                                                                            

box_citizenship <- ggplot(data = noNAs, design=nhc,
                      aes(x=log(monoEthyl), y=citizenship, fill=citizenship)) +
  scale_fill_brewer(palette="PuBuGn") +
  geom_boxplot() +
  theme(text = element_text(size=12)) +
  xlab("(logged) Mono-Ethyl Phthalate Level (ng/mL)") +
  ylab("Participant Citizenship Status") +
ggtitle("Participant Citizenship Status and Logged Phthalate Level")


box_citizenship
```








## Ordinary Least Squares (OLS)
website: https://www.statology.org/ols-regression-in-r/
Ordinary least squares (OLS) regression is a method that allows us to find a line that best describes the relationship between one or more predictor variables and a response variable

## Akaike Information Criterion (AIC)
AIC is an estimator of prediction error and thereby relative quality of statistical models for a given set of data.

```{r}
ols1 <- (svyglm(log(monoEthyl)~1, design=nhc, na.action = na.omit))
ols1
# this gives an AIC of 88140
## ^^ this is just practice... from the article I read online
### what does ~1 mean?

# modela <- svyglm(log(monoEthyl)~refED+age+gender+ethnicity+fpl+citizenship, design=nhc, na.action = na.omit)
ols_a <- (svyglm(log(monoEthyl)~refED+age+gender+ethnicity+fpl+citizenship, design=nhc, na.action = na.omit))
ols_a
# this gives an AIC of 77,730

# modelb <- svyglm(log(monoEthyl)~refED+age+ethnicity+fpl+citizenship, design=nhc, na.action = na.omit)
ols_b <- (svyglm(log(monoEthyl)~refED+age+ethnicity+fpl+citizenship, design=nhc, na.action = na.omit))
ols_b
# this gives an AIC of 77,730
# this means that taking gender out does not improve or decrease the prediction of monoEthyl?

# modelc <- svyglm(log(monoEthyl)~refED+age+ethnicity+fpl, design=nhc, na.action = na.omit)
ols_c <- (svyglm(log(monoEthyl)~refED+age+ethnicity+fpl, design=nhc, na.action = na.omit))
ols_c
# this gives an AIC of 77,810

#(try)
# take out ethnicity
ols_d <- (svyglm(log(monoEthyl)~refED+age+fpl+citizenship, design=nhc, na.action = na.omit))
ols_d
# this gives an AIC of 78,430

# take out age
ols_e <- (svyglm(log(monoEthyl)~refED+ethnicity+fpl+citizenship, design=nhc, na.action = na.omit))
ols_e
# this gives an AIC of 77,910

# take out refED
ols_f <- (svyglm(log(monoEthyl)~age+ethnicity+fpl+citizenship, design=nhc, na.action = na.omit))
ols_f
# this gives an AIC of 80,310

# take out fpl
ols_g <- (svyglm(log(monoEthyl)~refED+age+ethnicity+citizenship, design=nhc, na.action = na.omit))
ols_g
# this gives an AIC of 83,550

# take out citizenship
ols_h <- (svyglm(log(monoEthyl)~refED+age+ethnicity+fpl, design=nhc, na.action = na.omit))
ols_h
# this gives an AIC of 77,810

# add in childED 
ols_i <- (svyglm(log(monoEthyl)~refED+age+ethnicity+fpl+citizenship+childED, design=nhc, na.action = na.omit))
ols_i
# this gives an AIC of 24,800

# add in adultED
ols_j <- (svyglm(log(monoEthyl)~refED+age+ethnicity+fpl+citizenship+adultED, design=nhc, na.action = na.omit))
ols_j
# this gives an AIC of 49,030
```


```{r}
predmarg<-svypredmeans(ols1, ~interaction(gender,ethnicity))
predmarg
```


## Non-parametric tests

Non-parametric tests can also be done. Let’s start with a Wilcoxon signed rank test, which is the non-parametric analog of an independent-samples t-test.

```{r}
wil <- svyranktest(log(monoEthyl)~age, design = nhc, na = TRUE, test = c("wilcoxon"))
wil
```

This is an example of a median test.

```{r}
mtest <- svyranktest(log(monoEthyl)~age, design = nhc, na = TRUE, test=("median"))
mtest
```

This is an example of a Kruskal Wallis test, which is the non-parametric analog of a one-way ANOVA.
```{r}
kwtest <- svyranktest(log(monoEthyl)~refED, design = nhc, na = TRUE, test=("KruskalWallis"))
kwtest
```

## Logistic regression
Let’s see a few examples of logistic regression.
"as.factor" is key to getting this code running

```{r}
logit1 <- (svyglm(as.factor(log(monoEthyl))~as.factor(refED)+RIDAGEYR, family=quasibinomial, design=nhc, na.action = na.omit))
summary(logit1)
```

Logistic regression on a subpopulation (respondents over age 20).

```{r}
subset1 <- subset(nhc, RIDAGEYR > 18)
logit2 <- (svyglm(as.factor(log(monoEthyl))~as.factor(refED)+RIDAGEYR, family=quasibinomial, design=subset1, na.action = na.omit))
summary(logit2)
```

We can also get a Wald test for a variable in the model.

```{r}
regTermTest(logit2, ~RIDAGEYR)
```

Instead of getting an R-squared value as you do in linear regression, a pseudo-R-squared is given in logistic regression. 
There are many different versions of pseudo-R-squared, and two of them are available with the psrsq function.

```{r}
psrsq(logit2, method = c("Cox-Snell"))

psrsq(logit2, method = c("Nagelkerke"))
```

## Ordered logistic regression

Below is an example of an ordered logistic regression. Note that the outcome variable must be a factor.

```{r}
ologit1 <- svyolr(as.factor(ethnicity)~as.factor(gender)+as.factor(citizenship)+RIDAGEYR, design = nhc, method = c("logistic"))
summary(ologit1)
```

## Other types of analyses available in the survey package

There are many more types of analyses that are available in the survey package and in other packages that work with complex survey data. A few examples:

Principle components analysis (PCA).

```{r}
pc <- svyprcomp(~monoEthyl+gender+refED, design=nhc,scale=TRUE,scores=TRUE)
pc
```

Cronbach’s alpha.

```{r}
svycralpha(~log(monoEthyl)+RIDAGEYR, design=nhc, na.rm = TRUE)
```







